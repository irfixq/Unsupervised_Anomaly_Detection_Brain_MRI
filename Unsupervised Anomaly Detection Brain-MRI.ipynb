{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cjIFrxl4xpb"
   },
   "source": [
    "# Unsupervised Anomaly Detection Brain-MRI\n",
    "\n",
    "Jupyter notebook for running all the experiments from our [paper](https://arxiv.org/abs/2004.03271). \n",
    "\n",
    "Hyperparameters may have to be adjusted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcltK7e6r5A"
   },
   "source": [
    "## Preperation\n",
    "\n",
    "### Imports and installation of the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LI-mX3ic4zBC"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "import os, glob\n",
    "! pip install pynrrd\n",
    "! pip install SimpleITK\n",
    "! pip install bunch\n",
    "! pip install nibabel\n",
    "! pip install medpy\n",
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlBFG8cb9zRr"
   },
   "source": [
    "### Get Code\n",
    "Clone Code from github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmL1urt8-F1a"
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/StefanDenn3r/Unsupervised_Anomaly_Detection_Brain_MRI\n",
    "# ! cd Unsupervised_Anomaly_Detection_Brain_MRI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo5Rut3WcSHH"
   },
   "source": [
    "### Google Drive mount\n",
    "Mounting Google Drive to access datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBFA_7f5cUe0"
   },
   "outputs": [],
   "source": [
    "# drive.mount('gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Irfixq\\\\Desktop\\\\P2\\\\Code 1\\\\Unsupervised_Anomaly_Detection_Brain_MRI-master'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRn8HOi7rSvV"
   },
   "source": [
    "### Tensorboard and tunneling\n",
    "Install ngrok for tunneling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc71w6qerQtF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
    "    os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "\n",
    "if os.path.exists(\"ngrok\"):\n",
    "    os.remove(\"ngrok\")\n",
    "  \n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQ6JZY18fS4G"
   },
   "source": [
    "Start tensorboard and forward port with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kele9MJBfAVK"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'logs/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fGr1nvVqduU"
   },
   "source": [
    "Extract ngrok url for accessing tensorboard\n",
    "\n",
    "**Attention**: Sometimes it throws an error like this:\n",
    "```\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "```\n",
    "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOJxnfekqPg2"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8QsqbYA53MI"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1xgAd-K4Q30"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets\n",
    "from trainers.AE import AE\n",
    "from trainers.VAE import VAE\n",
    "from trainers.CE import CE\n",
    "from trainers.ceVAE import ceVAE\n",
    "from trainers.VAE_You import VAE_You\n",
    "from trainers.GMVAE import GMVAE\n",
    "from trainers.GMVAE_spatial import GMVAE_spatial\n",
    "from trainers.fAnoGAN import fAnoGAN\n",
    "from trainers.ConstrainedAAE import ConstrainedAAE\n",
    "from trainers.ConstrainedAE import ConstrainedAE\n",
    "from trainers.AnoVAEGAN import AnoVAEGAN\n",
    "from models import autoencoder, variational_autoencoder, context_encoder_variational_autoencoder, variational_autoencoder_Zimmerer, context_encoder_variational_autoencoder, context_encoder_variational_autoencoder_Zimmerer,  gaussian_mixture_variational_autoencoder_You, gaussian_mixture_variational_autoencoder_spatial, gaussian_mixture_variational_autoencoder, fanogan, fanogan_schlegl, constrained_autoencoder, constrained_adversarial_autoencoder, constrained_adversarial_autoencoder_Chen, anovaegan\n",
    "from utils import Evaluation\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets, Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xogLARJl_B0K"
   },
   "source": [
    "Set paths to datasets and where to save checkpoints and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgkGf2LO35hI"
   },
   "outputs": [],
   "source": [
    "def get_CONFIG(timestamp=None):\n",
    "  current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "  if timestamp:\n",
    "    current_time=timestamp\n",
    "  dataset_root = \"C:/Users/Irfixq/Desktop/P2/Code 1/Unsupervised_Anomaly_Detection_Brain_MRI-master\"\n",
    "  save_dir = \"C:/Users/Irfixq/Desktop/P2/Code 1/Unsupervised_Anomaly_Detection_Brain_MRI-master\"\n",
    "  CONFIG = {\n",
    "    \"BRAINWEBDIR\": os.path.join(dataset_root, 'Brainweb'),\n",
    "    \"MSSEG2008DIR\": os.path.join(dataset_root, 'MSSEG2008'),\n",
    "    \"MSISBI2015DIR\": os.path.join(dataset_root, 'ISBIMSlesionChallenge'),\n",
    "    \"MSLUBDIR\": os.path.join(dataset_root, 'MSlub'),\n",
    "    \"CHECKPOINTDIR\": os.path.join(save_dir, 'checkpoints', current_time),\n",
    "    \"SAMPLEDIR\": os.path.join(save_dir, 'sample_dir', current_time),\n",
    "  }\n",
    "  return CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L41jcwBrqkev"
   },
   "source": [
    "### Manual Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-a9c5c4qaiK"
   },
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Q8IFuKHqEiI"
   },
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBobdPWvXBsl"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-pIg1uHQufK"
   },
   "source": [
    "**VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia25A9wli8d6"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2WmjqCqp3S4"
   },
   "source": [
    "#### ceVAE - Variations\n",
    "\n",
    "Paper: [Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection](https://arxiv.org/abs/1812.05941)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsxKL2xIXhrL"
   },
   "source": [
    "**CE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ed4PbNOc2P50"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=CE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = CE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlPoFhpyLgqs"
   },
   "source": [
    "**ceVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ujv7TbWVuA5"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.use_gradient_based_restoration = 0.002\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder.context_encoder_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruwGvgCnuPQ8"
   },
   "source": [
    "**VAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtNu_izGM8FO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder_Zimmerer.variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9lhvpN6mu7QT"
   },
   "source": [
    "**ceVAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szrN4m0eu6xM"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=1, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder_Zimmerer.context_encoder_variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Oc6ISRcqJMI"
   },
   "source": [
    "#### GMVAE-(Restoration)-Variations\n",
    "\n",
    "Paper: [Unsupervised Lesion Detection via Image Restoration with a Normative Prior](https://openreview.net/forum?id=S1xg4W-leV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZmw9-2HO61B"
   },
   "source": [
    "**VAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAF3eVrCPAdG"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE_You, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE_You(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhllMocWpww9"
   },
   "source": [
    "**GMVAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmRGUPN86DTX"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 1\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_You.gaussian_mixture_variational_autoencoder_You)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azCAeseN3t6i"
   },
   "source": [
    "**GMVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5HNY5v-qCxO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 128\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE(tf.Session(), config, network=gaussian_mixture_variational_autoencoder.gaussian_mixture_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_GIxM1KGN2-"
   },
   "source": [
    "**GMVAE-spatial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9G0foovGNWI"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_spatial.gaussian_mixture_variational_autoencoder_spatial)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdIb36bv-yji"
   },
   "source": [
    "#### f-AnoGAN\n",
    "\n",
    "Paper: [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks.](https://www.ncbi.nlm.nih.gov/pubmed/30831356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3h_nH3F-0PP"
   },
   "source": [
    "**Unified f-AnoGan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj70VsVlAjIj"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan.fanogan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JP-2nm-jYBuQ"
   },
   "source": [
    "**f-AnoGAN - Schlegl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hclZeagWA6Rf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[16, 16], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan_schlegl.fanogan_schlegl)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0D7zuB62DR0"
   },
   "source": [
    "#### Constrained Adversarial AE\n",
    "\n",
    "Paper: [Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders](https://arxiv.org/abs/1806.04972)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh6Tvwe02OWA"
   },
   "source": [
    "**constrained AAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPBnr3r32LGf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder.constrained_adversarial_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mR-WjhNv0Mo"
   },
   "source": [
    "**constrained AAE Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_HhaHSr4Of9"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder_Chen.constrained_adversarial_autoencoder_Chen)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aMjd0DR236b"
   },
   "source": [
    "#### AnoVAEGAN\n",
    "\n",
    "Paper: [Deep autoencoding models for unsupervised anomaly segmentation in brain MR images](https://arxiv.org/abs/1804.04488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdHKBg3B2-6W"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AnoVAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AnoVAEGAN(tf.Session(), config, network=anovaegan.anovaegan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XhjDLN73NC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1-a9c5c4qaiK",
    "P2WmjqCqp3S4",
    "9Oc6ISRcqJMI",
    "qdIb36bv-yji",
    "U0D7zuB62DR0"
   ],
   "machine_shape": "hm",
   "name": "Unsupervised Anomaly Detection Brain-MRI.ipynb",
   "provenance": [
    {
     "file_id": "1SnihwKuEnP605BZEL1vdlGPA_xM6Bpgk",
     "timestamp": 1567420278659
    },
    {
     "file_id": "1Y14H2kevErX7LCln3-8yHXNQtnykb3m9",
     "timestamp": 1566387374003
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
